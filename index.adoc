
= ATIVIDADES PROCESSAMENTO DIGITAL DE IMAGENS

[.text-center]
== ATIVIDADES UNIDADE 1:

[.text-center]
== MANIPULANDO PIXELS EM UMA IMAGEM

=== 3.2 - EXERCÍCIO 1:

==== Regiões:

[.text-left]  
  Utilizando o programa exemplos/pixels.cpp como referência, implemente um programa regions.cpp. Esse programa deverá solicitar ao usuário as coordenadas de dois pontos P1P1 e P2P2 localizados dentro dos limites do tamanho da imagem e exibir que lhe for fornecida. Entretanto, a região definida pelo retângulo de vértices opostos definidos pelos pontos P1P1 e P2P2 será exibida com o negativo da imagem na região correspondente. 

[.text-center]
=== SOLUÇÃO:

O exercício em questão foi feito utilizando-se da imagem abaixo:

image::imagem.jpg[500,500,float="center",align="center"]

E após execução do algoritmo regions implementado obtivemos o resultado abaixo:

image::regions.png[500,500,float="center",align="center"]

.regions.cpp

[source,cpp,numbered]
[.text-left]

----

#include <cv.h>
#include <highgui.h>
#include <stdio.h>
#include <iostream>
#include <string.h>

using namespace std;
using namespace cv;

int main(int, char**){
  Mat image;
  Vec3b val;
  int x1,x2,y1,y2;

  image= imread("imagem.jpg",CV_LOAD_IMAGE_GRAYSCALE);
 
  cout << "Digite P1 : ";
  cin >>  x1;
  cout << "Digite P1 : ";
  cin >>  y1;
  cout << "Digite P2 : ";
  cin >>  x2;
  cout << "Digite P2 : ";
  cin >>  y2;

   for (int i = x1; i < x2; ++i)
        {
             for (int j = y1; j < y2; ++j)
             {
            image.at<uchar>(i,j) = 255 - image.at<uchar>(i,j);
         }
        }

 
  imshow("janela", image);  
  waitKey();
  return 0;
}

----

=== 3.2 - EXERCÍCIO 2:
  
[.text-left]  
  Utilizando o programa exemplos/pixels.cpp como referência, implemente um programa trocaregioes.cpp. Seu programa deverá trocar os quadrantes em diagonal na imagem. Explore o uso da classe Mat e seus construtores para criar as regiões que serão trocadas.

[.text-left] 
Após implementação e execução do programa trocaregioes.cpp foi obtido o resultado abaixo, já mostrando a imagem de entrada, a imagem em tons de cinza e a imagem com o efeito aplicado.

image::trocaregioes.png[800,800,float="center",align="center"]

Código trocaregioes.cpp

.trocaregioes.cpp

[source,cpp,numbered]
[.text-left]

----

#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <iostream>
#include <algorithm>
#include <stdlib.h>
#include <time.h>

using namespace cv;
using namespace std;

int px_1, py_1, px_2, py_2;
bool clicado = false;
Mat imgOriginal;        
Mat imgGrayscale;       
Mat imgResult;          
Mat listOfRoi[4];       


void pickARoi() {
    int index[4] = { 0,1,2,3 };

    srand(time(0));
    random_shuffle(begin(index), end(index));

    int ind1 = index[0];
    int ind2 = index[1];
    int ind3 = index[2];
    int ind4 = index[3];

    // imprimindo apenas para checar a ordem
   cout << "\n\nOrdem : { " << ind1 << ", " << ind2 << ", " << ind3 << ", " << ind4 << " }\n\n";

    listOfRoi[ind1].copyTo(imgResult(Rect(0,                    0,                          listOfRoi[ind1].cols,   listOfRoi[ind1].rows)));    
    listOfRoi[ind2].copyTo(imgResult(Rect(listOfRoi[ind1].cols, 0,                          listOfRoi[ind2].cols,   listOfRoi[ind2].rows)));    
    listOfRoi[ind3].copyTo(imgResult(Rect(0,                    listOfRoi[ind1].rows,       listOfRoi[ind3].cols,   listOfRoi[ind3].rows)));    
    listOfRoi[ind4].copyTo(imgResult(Rect(listOfRoi[ind1].cols, listOfRoi[ind1].rows,       listOfRoi[ind4].cols,   listOfRoi[ind4].rows)));    
}

int main() {

    string arquivo;                            
    cout << "Digite o nome do arquivo : ";
    cin >> arquivo;                            
    imgOriginal = imread(arquivo);          

    if (imgOriginal.empty()) {                                                             
        cout << "error: o arquivo --> " << arquivo << " <-- n„o pode ser lido!\n\n";     
        system("pause");
        return(0);                                                                              // saindo do programa
    }

    cvtColor(imgOriginal, imgGrayscale, CV_BGR2GRAY);      
    
    namedWindow("imgOriginal", CV_WINDOW_AUTOSIZE);
    namedWindow("imgGrayscale", CV_WINDOW_AUTOSIZE);
    namedWindow("imgResult", CV_WINDOW_AUTOSIZE);

    int col_half = imgOriginal.cols / 2;
    int row_half = imgOriginal.rows / 2;

    cout << "\n\nWidth : " << imgOriginal.cols << "px\n";
    cout << "Height : " << imgOriginal.rows << "px\n\n";
   
    Rect roi1(0,            0,          col_half,   row_half);      
    Rect roi2(col_half,     0,          col_half,   row_half);      
    Rect roi3(0,            row_half,   col_half,   row_half);      
    Rect roi4(col_half,     row_half,   col_half,   row_half);      

    listOfRoi[0] = Mat(imgGrayscale, roi1);
    listOfRoi[1] = Mat(imgGrayscale, roi2);
    listOfRoi[2] = Mat(imgGrayscale, roi3);
    listOfRoi[3] = Mat(imgGrayscale, roi4);

    imgResult = Mat(imgGrayscale.rows, imgGrayscale.cols, imgGrayscale.type());

    pickARoi();

    imshow("imgOriginal", imgOriginal);
    imshow("imgGrayscale", imgGrayscale);
    imshow("imgResult", imgResult);

    waitKey(0);
    return(0);
}

----

[.text-center]
== PREENCHENDO REGIÕES

[.text-center]
=== 4.2 - EXERCÍCIOS:

  1 - Observando-se o programa labeling.cpp como exemplo, é possível verificar que caso existam mais de 255 objetos na cena, o processo de rotulação poderá ficar comprometido. Identifique a situação em que isso ocorre e proponha uma solução para este problema.

  2 - Aprimore o algoritmo de contagem apresentado para identificar regiões com ou sem buracos internos que existam na cena. Assuma que objetos com mais de um buraco podem existir. Inclua suporte no seu algoritmo para não contar bolhas que tocam as bordas da imagem. Não se pode presumir, a priori, que elas tenham buracos ou não.

[.text-center]
=== SOLUÇÃO:

[.text-left]
1) Mesmo que o contador seja maior que os 255, só há como o computador representar 255 tons de cinza. Dessa forma, na forma como o programa labeling.cpp está implementado, depois que o contador ultrapassar o nível de cinza 255, todos os objetos que passarem pelo processamento do floodFill terão seus níveis de cinza iguais a 255.

Solução proposta para o problema:

.contagem.cpp

[source,cpp,numbered]
[.text-left]

----

#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
    Mat image;
    int width, height;
    int contadorObjetos, tonDeCinza;

    CvPoint p;
    image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

    if(!image.data){
        std::cout << "imagem nao carregou corretamente\n";
        return(-1);
    }
    width=image.size().width;
    height=image.size().height;

    p.x=0;
    p.y=0;

    // busca objetos com buracos presentes
    tonDeCinza=0;
    contadorObjetos = 0;

    for(int i=0; i<height; i++){
        for(int j=0; j<width; j++){
          if(image.at<uchar>(i,j) == 255){
            // achou um objeto
            tonDeCinza++;
            contadorObjetos++;

            p.x=j;
            p.y=i;
            floodFill(image,p,tonDeCinza);

            if(tonDeCinza >= 255)
                tonDeCinza = 0;
          }
        }
    }

    cout << "Qtd. objetos: " << contadorObjetos << endl;

    imshow("image", image);
    waitKey();

    return 0;
}

----

[.text-left]
2)Para a segunda parte do exercício foi implementado o programa abaixo em que ntes de tudo, desenhamos um retângulo com nível de cinza igual a 255 na borda da imagem. Depois disso, utilizamos a função floodFill no primeiro pixel da imagem mudando os valores dos tons dos pixels para zero. E com isso, os objetos que estavam em contato com esse retangulo foram imediatamente excluidos.

.buracos.cpp

[source,cpp,numbered]
[.text-left]

----

#include <iostream>
#include <cv.h>
#include "opencv2/highgui/highgui.hpp"
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
    Mat image;
    int width, height;
    const int tonDeCinzaPreto = 0, tonDeCinzaBranco = 255;
    const int novaCorFundo = 100, novaCorObjeto = 200;
    int contadorObjetosSemBuraco, contadorObjetosComBuraco;

    CvPoint p;
    image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

    if(!image.data){
        std::cout << "imagem nao carregou corretamente\n";

        return(-1);
    }

    width = image.size().width;
    height = image.size().height;

    p.x = 0;
    p.y = 0;

    contadorObjetosSemBuraco = 0;
    contadorObjetosComBuraco = 0;

    Mat novaImagem = Mat::ones(width + 2, height + 2, CV_8U)*tonDeCinzaBranco;
    Mat(image, Rect(0, 0, width, height)).copyTo(Mat(novaImagem, Rect(1,1,width, height)));

    floodFill(novaImagem,p,tonDeCinzaPreto);

    floodFill(novaImagem,p,novaCorFundo);

    for(int i=0; i<height; i++){
        for(int j=0; j<width; j++){
            if(novaImagem.at<uchar>(i,j) == tonDeCinzaBranco){
                p.x=j;
                p.y=i;
                floodFill(novaImagem,p,novaCorObjeto);
                contadorObjetosSemBuraco++;
            }else if(novaImagem.at<uchar>(i,j) == tonDeCinzaPreto){
                p.x=j;
                p.y=i;
                floodFill(novaImagem,p,novaCorFundo);
                contadorObjetosComBuraco++;
            }
        }
    }

    p.x = 0;
    p.y = 0;
    floodFill(novaImagem,p,tonDeCinzaPreto);

    cout << "Qtd. objetos: " << contadorObjetosSemBuraco << endl;
    cout << "Qtd. objetos sem buraco: " << contadorObjetosSemBuraco - contadorObjetosComBuraco << endl;
    cout << "Qtd. objetos com buraco: " << contadorObjetosComBuraco << endl;

    imshow("bolhas.png", image);

    imwrite("novaImagem.png", novaImagem);
    imshow("Nova Imagem", novaImagem);

    waitKey();
    return 0;
}

----

E após a execução do programa obemos o resultado abaixo:

image::resultbolhas.png[800,800,float="center",align="center"]

[.text-center]
== MANIPULAÇÃO DE HISTOGRAMAS

[.text-center]
=== 5.2.1 - EXERCÍCIO:

[.text-left]
  Utilizando o programa exemplos/histogram.cpp como referência, implemente um programa equalize.cpp. Este deverá, para cada imagem capturada, realizar a equalização do histogram antes de exibir a imagem. Teste sua implementação apontando a câmera para ambientes com iluminações variadas e observando o efeito gerado. Assuma que as imagens processadas serão em tons de cinza.

=== SOLUÇÃO:

[.text-left]
Para este primeiro problema exposto na parte de manipulação de histogramas, o programa utiliza da webcam do dispositivo em que está sendo executado, em que a captura dos frames é feito pela classe VideoCapture. A imagem capturada é então convertida para tons de cinza usando a função cvtColot(Mat, Mat, CV_BGR2GRAY) e essa imagem em tons de cinza tem é equalizada fazendo-se uso da função equalizeHist(Mat, Mat), que tem como entrada a imagem a ser equalizada e a imagem, ou elemento da classe Mat, que irá armazenar a imagem equalizada.

.equalize.cpp

[source,cpp,numbered]
[.text-left]

----

#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;
  Mat equalizedImage;
  Mat imageGray;
  int width, height;
  //objeto de captura de frames
  VideoCapture cap;
  //vetor contendo as porcoes r g b da imagem
  vector<Mat> planes;
  //histogramas
  Mat histR, histG, histB;
  //tamanho do vetor histograma
  int nbins = 64;
  //parametros para calculo do histograma
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  cap.open(0);//inicia objeto para captura de imagens

  //testa abertura
  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }

  //le altura e largura do frame sendo capturado
  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  //mostra altura e largura na tela 
  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  //define largura e altura do histograma
  int histw = nbins, histh = nbins/2;
  //cria elemento para desenhar os histogramas
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgG(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgB(histh, histw, CV_8UC3, Scalar(0,0,0));

  while(1){
    cap >> image;//transfere o frama capturado para o elemento tipo Mat
    split (image, planes);//divide os valores r,g e b em elementos diferentes
    //calcula histograma de cada elemento de cor
    calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[1], 1, 0, Mat(), histG, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[2], 1, 0, Mat(), histB, 1,
             &nbins, &histrange,
             uniform, acummulate);
    //normaliza os histogramas
    normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histG, histB, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histB, histB, 0, histImgR.rows, NORM_MINMAX, -1, Mat());

    //pinta os elementos dos histogramas todo de preto
    histImgR.setTo(Scalar(0));
    histImgG.setTo(Scalar(0));
    histImgB.setTo(Scalar(0));

    //desenha histograma
    for(int i=0; i<nbins; i++){
      line(histImgR, Point(i, histh),
           Point(i, cvRound(histR.at<float>(i))),
           Scalar(0, 0, 255), 1, 8, 0);
      line(histImgG, Point(i, histh),
           Point(i, cvRound(histG.at<float>(i))),
           Scalar(0, 255, 0), 1, 8, 0);
      line(histImgB, Point(i, histh),
           Point(i, cvRound(histB.at<float>(i))),
           Scalar(255, 0, 0), 1, 8, 0);
    }
    histImgR.copyTo(image(Rect(0, 0       ,nbins, histh)));
    histImgG.copyTo(image(Rect(0, histh   ,nbins, histh)));
    histImgB.copyTo(image(Rect(0, 2*histh ,nbins, histh)));
    imshow("image", image);

    //converte imagem para tons de cinza
    cvtColor(image, imageGray, CV_BGR2GRAY);
    //equaliza a imagem em tons de cinza
    equalizeHist(imageGray, equalizedImage);
    
    imshow("Equalized Gray Image", equalizedImage);

    if(waitKey(27) >= 0) break;
  }
  return 0;
}

----

E o resultado após a execução do programa está mostrado na imagem abaixo:

image::equalize.png[800,800,float="center",align="center"]

[.text-center]
=== 5.2.2 - EXERCÍCIO:

[.text-left]
  Utilizando o programa exemplos/histogram.cpp como referência, implemente um programa motiondetector.cpp. Este deverá continuamente calcular o histograma da imagem (apenas uma componente de cor é suficiente) e compará-lo com o último histograma calculado. Quando a diferença entre estes ultrapassar um limiar pré-estabelecido, ative um alarme. Utilize uma função de comparação que julgar conveniente.

=== SOLUÇÃO:

[.text-left]
O programa motiondetector.cpp, assim como o equalize.cpp utiliza a classe VidioCapturepara capturar imagens através de uma webcam disponível no dispositivo em que está sendo executada.

.motiondetector.cpp

[source,cpp,numbered]
[.text-left]

----

#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;
  int width, height;
  VideoCapture cap;
  Mat hist, oldHist;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  cap.open(0);
  
  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }
  
  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  int histw = nbins, histh = nbins/2;
  Mat histImg(histh, histw, CV_8UC1, Scalar(0));
  int count = 0; 
  double histDiff = 0; 

  while(1){   
    cap >> image;
    cvtColor(image, image, CV_BGR2GRAY);

    calcHist(&image, 1, 0, Mat(), hist, 1,
             &nbins, &histrange,
             uniform, acummulate);
    normalize(hist, hist, 0, histImg.rows, NORM_MINMAX, -1, Mat());

    histImg.setTo(Scalar(0));

    for(int i=0; i<nbins; i++){
      line(histImg, Point(i, histh),
           Point(i, cvRound(hist.at<float>(i))),
           Scalar(255), 1, 8, 0);
   }
    
    histImg.copyTo(image(Rect(0, 0       ,nbins, histh)));
    imshow("image", image);
    
    if(count >=1)
       histDiff = compareHist(hist, oldHist, 0);
   
    if( histDiff < 0.98)
       cout << "motion detected, histDiff = " << histDiff << endl;
    oldHist = hist.clone();
    count++;
    if(waitKey(30) >= 0) break;
  }
  return 0;
}

----

Os resultados após execução do programa podem ser vistos nas imagens abaixo:

image::motion.png[800,800,float="center",align="center"]

image::motion2.png[800,800,float="center",align="center"]

[.text-center]
== FILTRAGEM NO DOMÍNIO ESPACIAL I

[.text-center]
=== 6.2 - EXERCÍCIO:

[.text-left]
  Utilizando o programa exemplos/filtroespacial.cpp como referência, implemente um programa laplgauss.cpp. O programa deverá acrescentar mais uma funcionalidade ao exemplo fornecido, permitindo que seja calculado o laplaciano do gaussiano das imagens capturadas. Compare o resultado desse filtro com a simples aplicação do filtro laplaciano.

[.text-center]
=== SOLUÇÃO:

[.text-left]
Para obter o resultado do laplaciano do gaussiano é necessário filtrar a imagem dada com um filtro gaussiano e, logo após, utilizar o filtro laplaciano no resultado da filtragem anterior. 

.lapgauss.cpp

[source,cpp,numbered]
[.text-left]

----

#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m){
  for(int i=0; i<m.size().height; i++){
    for(int j=0; j<m.size().width; j++){
      cout << m.at<float>(i,j) << ",";
    }
    cout << endl;
  }
}

void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
  "a - calcular modulo\n"
    "m - media\n"
    "g - gauss\n"
    "v - vertical\n"
  "h - horizontal\n"
    "l - laplaciano\n"
    "x - laplaciano do gaussiano\n"
  "esc - sair\n";
}

int main(int argvc, char** argv){
  VideoCapture video;
  float media[] = {1,1,1,
           1,1,1,
           1,1,1};
  float gauss[] = {1,2,1,
           2,4,2,
           1,2,1};
  float horizontal[]={-1,0,1,
            -2,0,2,
            -1,0,1};
  float vertical[]={-1,-2,-1,
          0,0,0,
          1,2,1};
  float laplacian[]={0,-1,0,
           -1,4,-1,
           0,-1,0};

  Mat cap, frame, frame32f, frameFiltered, frameFiltered1;
  Mat mask(3,3,CV_32F), mask1;
  Mat result, result1;
  double width, height;
  int absolut;
  char key;
  bool laplgauss = false;

  video.open(0);
  if(!video.isOpened())
    return -1;

  width=video.get(CV_CAP_PROP_FRAME_WIDTH);
  height=video.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura=" << width << "\n";;
  cout << "altura =" << height<< "\n";;

  namedWindow("filtroespacial",1);

  mask = Mat(3, 3, CV_32F, media);
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
  swap(mask, mask1);
  absolut=1;

  menu();
  for(;;){
    video >> cap;
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);

    if(laplgauss){
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);
      mask = Mat(3, 3, CV_32F, laplacian);
      filter2D(frameFiltered, frameFiltered1, frameFiltered.depth(), mask, Point(1,1), 0);

      if(absolut){
        frameFiltered1=abs(frameFiltered1);
      }

      frameFiltered1.convertTo(result1, CV_8U);
      imshow("filtroespacial", result1);
    }
    else{
      filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);

      if(absolut){
        frameFiltered=abs(frameFiltered);
      }

      frameFiltered.convertTo(result, CV_8U);
      imshow("filtroespacial", result);
    }

    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
    case 'a':
    laplgauss = false;
      menu();
      absolut=!absolut;
      break;
    case 'm':
      menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      laplgauss = false;
      
      break;
    case 'g':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      laplgauss = false;
      
      break;
    case 'h':
      menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      laplgauss = false;

      break;
    case 'v':
      menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      laplgauss = false;

      break;
    case 'l':
      menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);
      laplgauss = false;

      break;
    case 'x':
     laplgauss = true;
     menu();

     break;
    default:
      break;
    }
  }
  return 0;
}

----

Após a execução do programa podemos obter os resultados abaixo:

- Imagem processada com o filtro laplaciano:

image::laplaciano.png[600,600,float="center",align="center"]

- Imagem processada com o Lapgauss, em que podemos observar uma certa quantidade menor de ruido:

image::lapgauss.png[600,600,float="center",align="center"]

[.text-center]
== ATIVIDADES UNIDADE 2:
:stem: latexmath

[.text-center]
== FILTRAGEM NO DOMÍNIO DA FREQUÊNCIA

[.text-center]
=== 8.2 - EXERCÍCIO:

[.text-left]
	Utilizando o programa exemplos/dft.cpp como referência, implemente o filtro homomórfico para melhorar imagens com iluminação irregular. Crie uma cena mal iluminada e ajuste os parâmetros do filtro homomórfico para corrigir a iluminação da melhor forma possível. Assuma que a imagem fornecida é em tons de cinza.

[.text-center]
=== SOLUÇÃO:

[.text-center]
**Filtragem Homomórfica**
[.text-left]
A filtragem homomórfica trata-se basicamente de uma abordagem que opera sobre as componentes de iluminação e reflectância separadamente. Em que ela atenua as baixas-frequências e realça as altas. 

Como mostrado na equação abaixo:

[.text-center]
stem:[f(x,y)=i(x,y)r(x,y)]
[.text-left]
Em que esse método de filtragem é deduzido na seguinte imagem:

image::homomorfic.png[500,500,float="center",align="center"]

[.text-left]
O filtro homomórfico funciona com a idéia de que a "iluminação" é a componente de baixa-frequência e a "reflectância" é a componente de alta-frequência. Onde aumenta-se o contraste se a iluminação é diminuida (i<1) e a reflectância é aumentada (r>1). 
Nessa transição pode-se utilizar qualquer curva, mas geralmente utiliza-se Butterworth ou Gaussiano. 

[.text-left]
Podemos ver na figura abaixo um corte transversal de um filtro como esse. 

image::grafic.png[500,500,float="center",align="center"]

[.text-left]
E logo abaixo temos também uma forma ligeiramente modificada do filtro passa-alta gaussiano.

image::formule.png[500,500,float="center",align="center"]

[.text-left]
Abaixo temos o código de implementação do filtro:

.homomorfic.cpp


[source,cpp,numbered]
[.text-left]

----

#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <math.h>

#define RADIUS 20

using namespace cv;
using namespace std;

Mat filter, tmp;
int dft_N, dft_M;
int dh_slider = 20;
int dh_slider_max = 100;

int dl_slider = 5;
int dl_slider_max = 100;

int c_slider = 5;
int c_slider_max = 100;

int d0_slider = 80;
int d0_slider_max = 1000;

char TrackbarName[50];

void slider(int, void*){
	int M,N;
	float D2, dh, dl, d0;
	M = dft_M;
	N = dft_N;
	dh = dh_slider/10.0;
	dl = dl_slider/10.0;
	d0 = d0_slider/10.0;
  //calculando o filtro homomorfico a partir do ajuste dos sliders da trackbar. 
	tmp = Mat(dft_M, dft_N, CV_32F);
	for(int i=0; i<dft_M ;i++)
		for(int j=0; j<dft_N ;j++){
				D2 = ((float)i-M/2.0)*((float)i-M/2.0) + ((float)j-N/2.0)*((float)j-N/2.0);
				tmp.at<float>(i,j) = (dh-dl)*(1.0-exp(-1.0*(float)c_slider*(D2/(d0*d0))))+ dl;
			}
	
  // cria a matriz com as componentes do filtro e junta
  // ambas em uma matriz multicanal complexa
  Mat comps[]= {tmp, tmp};
  merge(comps, 2, filter);

}

// troca os quadrantes da imagem da DFT
void deslocaDFT(Mat& image ){
  Mat A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para
  // evitar cÃƒÂ³pias de tamanho desigual
  image = image(Rect(0, 0, image.cols & -2, image.rows & -2));
  int cx = image.cols/2;
  int cy = image.rows/2;
  
  // reorganiza os quadrantes da transformada
  // A B   ->  D C
  // C D       B A
  A = image(Rect(0, 0, cx, cy));
  B = image(Rect(cx, 0, cx, cy));
  C = image(Rect(0, cy, cx, cy));
  D = image(Rect(cx, cy, cx, cy));

  // A <-> D
  A.copyTo(tmp);  D.copyTo(A);  tmp.copyTo(D);

  // C <-> B
  C.copyTo(tmp);  B.copyTo(C);  tmp.copyTo(B);
}

int main(int argc , char** argv){
  VideoCapture cap;   
  Mat imaginaryInput, complexImage, multsp;
  Mat padded, mag;
  Mat image, imagegray; 
  Mat_<float> realInput, zeros;
  vector<Mat> planos;

  // guarda tecla capturada
  char key;
	if(argc != 2){
		printf("ERRO\n");
		exit(-1);
	}
	image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE); // carrega a imagem

	cv::log(realInput, realInput);
  // identifica os tamanhos otimos para calculo da FFT
  dft_M = getOptimalDFTSize(image.rows);
  dft_N = getOptimalDFTSize(image.cols);

  // realiza o padding da imagem
  copyMakeBorder(image, padded, 0,
                 dft_M - image.rows, 0,
                 dft_N - image.cols,
                 BORDER_CONSTANT, Scalar::all(0));
	
  // parte imaginaria da matriz complexa (preenchida com zeros)
  zeros = Mat_<float>::zeros(padded.size());

  // prepara a matriz complexa para ser preenchida
  complexImage = Mat(padded.size(), CV_32FC2, Scalar(0));

  filter = complexImage.clone();	
	slider(1,0);
	
  for(;;){

    planos.clear();

    realInput = Mat_<float>(padded); 

    planos.push_back(realInput);
    planos.push_back(zeros);

    merge(planos, complexImage);

    dft(complexImage, complexImage);

    deslocaDFT(complexImage);

    mulSpectrums(complexImage,filter,complexImage,0);

    deslocaDFT(complexImage);

    idft(complexImage, complexImage);

    planos.clear();

  
    split(complexImage, planos);


    normalize(planos[0], planos[0], 0, 1, CV_MINMAX);
		// calcula a exponencial da imagem
		cv::exp(planos[0], planos[0]);

    normalize(planos[0], planos[0], 0, 1, CV_MINMAX);
    imshow("filtrada", planos[0]);

		key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
 
  	sprintf( TrackbarName, "H %d", dh_slider_max/10);
  	createTrackbar( TrackbarName, "filtrada",
				  &dh_slider,
				  dh_slider_max,
				  NULL); //funcao

		sprintf( TrackbarName, "L %d", dl_slider_max/10);
  	createTrackbar( TrackbarName, "filtrada",
				  &dl_slider,
				  dl_slider_max,
				  NULL); //funcao

		sprintf( TrackbarName, "C %d", c_slider_max/10);
  	createTrackbar( TrackbarName, "filtrada",
				  &c_slider,
				  c_slider_max,
				  NULL); //funcao

		sprintf( TrackbarName, "D0 %d", d0_slider_max/10);
  	createTrackbar( TrackbarName, "filtrada",
				  &d0_slider,
				  d0_slider_max,
				  NULL); //funcao 

		slider(d0_slider,0);
  }
  return 0;
}
----

[.text-left]
Abaixo mostramos a imagem original e ao lado a imagem com o filtro homomórfico aplicado. 

image::homomorficFilter.png[1000,10000,float="center",align="center"]

=== 11.1 - EXERCÍCIO:
[.text-left]

  * Utilizando os programas exemplos/canny.cpp e exemplos/pontilhismo.cpp como referência, implemente um programa cannypoints.cpp.
  A idéia é usar as bordas produzidas pelo algoritmo de Canny para melhorar a qualidade da imagem pontilhista gerada. A forma como a informação de borda será usada é livre. Entretanto, são apresentadas algumas sugestões de técnicas que poderiam ser utilizadas: 
  ** Desenhar pontos grandes na imagem pontilhista básica;
  ** Usar a posição dos pixels de borda encontrados pelo algoritmo de Canny para desenhar pontos nos respectivos locais na imagem gerada.
  ** Experimente ir aumentando os limiares do algoritmo de Canny e, para cada novo par de limiares, desenhar círculos cada vez menores nas posições encontradas. A Figura Pontilhismo aplicado à imagem Lena foi desenvolvida usando essa técnica.
  * Escolha uma imagem de seu gosto e aplique a técnica que você desenvolveu.
  * Descreva no seu relatório detalhes do procedimento usado para criar sua técnica pontilhista.

[.text-center]
=== SOLUÇÃO:
[.text-left]
O algoritmo de Canny de fato é útil para diversas aplicações em processamento de imagens e visão artificial. Informações de bordas podem ser usadas para melhorar algoritmos de segmentação automática ou para encontrar objetos em cenas e pontos de interesse. O pontilhismo é uma técnica de desenho impressionista onde o quadro é pintado usando apenas pontos.
[.text-left]
Nesta atividade o objetivo era o desenvolvimento do filtro de Canny para gerar uma imagem com pontilhismo. Em que inicialmente foi aplicado na imagem o processo do pontilhismo, e em seguida, a imagem bruta passou por algumas iterações do filtro de Canny, para que fosse possível delimitar suas bordas. Em cada uma das iterações o limiar do filtro é alterado com a intenção de obter uma imagem com menos bordas. Para as bordas ficarem mais destacadas foi necessário percorrer a imagem filtrada e desenhar um círculo em cada pixel que possuísse um tom de cinza maior que zero. E como saída é gereda e salva duas imagens editadas, onde a primeira(Imagem pontilhista.jpg) é a imagem com efeito de pontilhismo aplicado. 

.cannypoints.cpp

[source,cpp,numbered]
[.text-left]

----

  #include <iostream>
  #include <opencv2/opencv.hpp>
  #include <fstream>
  #include <iomanip>
  #include <vector>
  #include <algorithm>
  #include <numeric>
  #include <ctime>
  #include <cstdlib>

  using namespace std;
  using namespace cv;

  #define STEP 5
  #define JITTER 3
  #define RAIO 5

  int main(int argc, char** argv){
  Mat Original, borderOriginalImage;
  Mat Pontilhismo;
  int x, y, width, height, gray;
  //arrays de índices que servirão para identificar elementos da imagem de referência
  vector<int> yrange;
  vector<int> xrange;

  srand(time(0));

  Original= imread("imagem.jpg" ,CV_LOAD_IMAGE_GRAYSCALE);

  width = Original.size().width;
  height = Original.size().height;
  xrange.resize(height/STEP);
  yrange.resize(width/STEP);
  iota(xrange.begin(), xrange.end(), 0);
  iota(yrange.begin(), yrange.end(), 0);

  for(uint i=0; i<xrange.size(); i++){
    xrange[i]= xrange[i]*STEP+STEP/2;
  }

  for(uint i=0; i<yrange.size(); i++){
    yrange[i]= yrange[i]*STEP+STEP/2;
  }

  Original.copyTo(Pontilhismo);

  //Executa o pontilhismo;
  for(auto i : xrange){
    random_shuffle(yrange.begin(), yrange.end());
    for(auto j : yrange){
      x = i+rand()%(2*JITTER)-JITTER+1;
      y = j+rand()%(2*JITTER)-JITTER+1;
      gray = Original.at<uchar>(x,y);
      circle(Pontilhismo, cv::Point(y,x), RAIO, CV_RGB(gray,gray,gray), -1, CV_AA);
    }
  }

  imshow("Imagem Pontilhista", Pontilhismo);
  imwrite("imagemComPontilhismo.jpg", Pontilhismo);

   //Aplica Canny
   for(int z=0; z<5; z++){
     Canny(Original, borderOriginalImage, 10*z, 50*z);
     int raio = 5-z;

     for(int i=0; i<height; i++ ){
        for(int j=0; j<width; j++){
           if(borderOriginalImage.at<uchar>(i,j) == 255){
              gray = Original.at<uchar>(i,j);
              circle(Pontilhismo, cv::Point(j,i), raio, CV_RGB(gray,gray,gray), -1, CV_AA);
             }
        }
    }
    
    
  }
  imshow("Pontilhismo", Pontilhismo);
  imwrite("imagemComPontilhismo.jpg", Pontilhismo);
 

   waitKey();
  return 0;
}

----

Para esta aplicação foi utilizada como entrada, a imagem abaixo:


.Imagem de entrada para aplicação do algoritmo

image::imagem.jpg[500,500,float="center",align="center"]

E como saída foi obtida a imagem abaixo:

image::resultadocanny.png[1000,10000,float="center",align="center"]







